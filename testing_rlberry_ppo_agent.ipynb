{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlberry.agents.torch import PPOAgent\n",
    "from rlberry.envs.benchmarks.ball_exploration import PBall2D\n",
    "from rlberry.envs.benchmarks.ball_exploration.ball2d import BallLevel1, BallLevel2, BallLevel3, BallLevel4, BallLevel5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dict = {0 : PBall2D(),\n",
    "            1 : BallLevel1(),\n",
    "            2 : BallLevel2(),\n",
    "            3 : BallLevel3(),\n",
    "            4 : BallLevel4(),\n",
    "            5 : BallLevel5()}\n",
    "\n",
    "idx_to_env_dict = {0 : \"PBall2D\",\n",
    "            1 : \"BallLevel1\",\n",
    "            2 : \"BallLevel2\",\n",
    "            3 : \"BallLevel3\",\n",
    "            4 : \"BallLevel4\",\n",
    "            5 : \"BallLevel5\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Could not find least used device (nvidia-smi might be missing), use cuda:0 instead \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 5 | episode_rewards = 0.9662807639311587 | dw_time_elapsed = 3.036391500000036 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 10 | episode_rewards = 0.0 | dw_time_elapsed = 6.416708500000141 | fit/surrogate_loss = 0.03407394140958786 | fit/entropy_loss = 1.3526371717453003 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 16 | episode_rewards = 0.0 | dw_time_elapsed = 9.464892200000122 | fit/surrogate_loss = 0.03407394140958786 | fit/entropy_loss = 1.3526371717453003 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 21 | episode_rewards = 25.82635773371573 | dw_time_elapsed = 12.571341300000086 | fit/surrogate_loss = -0.017095591872930527 | fit/entropy_loss = 1.3367730379104614 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 27 | episode_rewards = 0.7328679786455448 | dw_time_elapsed = 15.585762800000111 | fit/surrogate_loss = 0.010619258508086205 | fit/entropy_loss = 1.3557562828063965 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 33 | episode_rewards = 0.0 | dw_time_elapsed = 18.66364599999997 | fit/surrogate_loss = 0.03340743109583855 | fit/entropy_loss = 1.3525112867355347 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 40 | episode_rewards = 0.0 | dw_time_elapsed = 21.711808200000178 | fit/surrogate_loss = -0.0052554309368133545 | fit/entropy_loss = 1.3525112867355347 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 48 | episode_rewards = 22.327477112920104 | dw_time_elapsed = 24.855416100000184 | fit/surrogate_loss = -0.015224091708660126 | fit/entropy_loss = 1.3366923332214355 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 56 | episode_rewards = 51.3093606461096 | dw_time_elapsed = 27.916563300000007 | fit/surrogate_loss = -0.0307245384901762 | fit/entropy_loss = 1.3660023212432861 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 64 | episode_rewards = 80.0092526874548 | dw_time_elapsed = 31.36081800000011 | fit/surrogate_loss = 0.023638665676116943 | fit/entropy_loss = 1.337299108505249 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 72 | episode_rewards = 80.80845163686995 | dw_time_elapsed = 34.55761340000004 | fit/surrogate_loss = 0.039562974125146866 | fit/entropy_loss = 1.305082082748413 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 80 | episode_rewards = 107.6252250501565 | dw_time_elapsed = 37.63494460000015 | fit/surrogate_loss = 0.003787122666835785 | fit/entropy_loss = 1.2722830772399902 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 88 | episode_rewards = 139.50566689311802 | dw_time_elapsed = 40.645908299999974 | fit/surrogate_loss = -0.012075746431946754 | fit/entropy_loss = 1.3250683546066284 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 97 | episode_rewards = 157.804087502478 | dw_time_elapsed = 43.95117189999996 | fit/surrogate_loss = 0.05830274522304535 | fit/entropy_loss = 1.207276463508606 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 106 | episode_rewards = 170.3207988471813 | dw_time_elapsed = 47.06471510000006 | fit/surrogate_loss = 0.02214953675866127 | fit/entropy_loss = 1.1793208122253418 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 115 | episode_rewards = 177.96506874776904 | dw_time_elapsed = 50.1990052000001 | fit/surrogate_loss = 0.06101882457733154 | fit/entropy_loss = 1.1507534980773926 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 123 | episode_rewards = 184.38806286990808 | dw_time_elapsed = 53.22470520000002 | fit/surrogate_loss = 0.03444402664899826 | fit/entropy_loss = 1.0654360055923462 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 132 | episode_rewards = 186.54454441905247 | dw_time_elapsed = 56.24011870000004 | fit/surrogate_loss = 0.0035444870591163635 | fit/entropy_loss = 1.0956435203552246 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 141 | episode_rewards = 198.541014581252 | dw_time_elapsed = 59.27299760000005 | fit/surrogate_loss = 0.0017435364425182343 | fit/entropy_loss = 1.0332119464874268 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 149 | episode_rewards = 195.33807116915403 | dw_time_elapsed = 62.3140449 | fit/surrogate_loss = 0.025474615395069122 | fit/entropy_loss = 1.0671919584274292 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 158 | episode_rewards = 199.15603638151833 | dw_time_elapsed = 65.42331209999998 | fit/surrogate_loss = 0.04412622004747391 | fit/entropy_loss = 0.9548322558403015 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 167 | episode_rewards = 202.37650675435884 | dw_time_elapsed = 68.5625199000001 | fit/surrogate_loss = 0.019590964540839195 | fit/entropy_loss = 0.8515081405639648 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 176 | episode_rewards = 203.49152678299848 | dw_time_elapsed = 71.85836960000006 | fit/surrogate_loss = 0.01048832107335329 | fit/entropy_loss = 0.9328355193138123 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 183 | episode_rewards = 204.5263773931793 | dw_time_elapsed = 75.04340530000013 | fit/surrogate_loss = 0.02017686888575554 | fit/entropy_loss = 0.7737116813659668 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 191 | episode_rewards = 205.4682613114749 | dw_time_elapsed = 78.24850630000014 | fit/surrogate_loss = 0.011696696281433105 | fit/entropy_loss = 0.8755971789360046 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 197 | episode_rewards = 207.08841986686903 | dw_time_elapsed = 81.3020242 | fit/surrogate_loss = -0.002263568341732025 | fit/entropy_loss = 0.7386694550514221 |  \n",
      "[INFO] Could not find least used device (nvidia-smi might be missing), use cuda:0 instead \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 8 | episode_rewards = 76.30723978505569 | dw_time_elapsed = 3.229670599999963 | fit/surrogate_loss = 0.006768472492694855 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 16 | episode_rewards = 57.75888521571935 | dw_time_elapsed = 6.284313099999963 | fit/surrogate_loss = 0.01242142915725708 | fit/entropy_loss = 1.585899829864502 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 24 | episode_rewards = 140.0539764298726 | dw_time_elapsed = 9.814272699999947 | fit/surrogate_loss = 0.03642800450325012 | fit/entropy_loss = 1.5470221042633057 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 32 | episode_rewards = 136.93119202769975 | dw_time_elapsed = 13.401773399999911 | fit/surrogate_loss = 0.028864063322544098 | fit/entropy_loss = 1.5345404148101807 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 40 | episode_rewards = 142.1592486142846 | dw_time_elapsed = 16.907535999999936 | fit/surrogate_loss = 0.027842726558446884 | fit/entropy_loss = 1.4933241605758667 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 48 | episode_rewards = 126.7842463648003 | dw_time_elapsed = 20.410380199999963 | fit/surrogate_loss = 0.051598113030195236 | fit/entropy_loss = 1.5196529626846313 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 56 | episode_rewards = 150.04843410006768 | dw_time_elapsed = 23.667947599999934 | fit/surrogate_loss = 0.029335729777812958 | fit/entropy_loss = 1.5332958698272705 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 64 | episode_rewards = 167.92579439931257 | dw_time_elapsed = 27.27656479999996 | fit/surrogate_loss = 0.029974162578582764 | fit/entropy_loss = 1.4953805208206177 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 72 | episode_rewards = 205.25420242264326 | dw_time_elapsed = 30.345264899999847 | fit/surrogate_loss = 0.024203553795814514 | fit/entropy_loss = 1.5268781185150146 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 80 | episode_rewards = 193.09939013102695 | dw_time_elapsed = 33.58257329999992 | fit/surrogate_loss = 0.037065278738737106 | fit/entropy_loss = 1.5300614833831787 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 87 | episode_rewards = 210.54971465629558 | dw_time_elapsed = 36.62785789999998 | fit/surrogate_loss = 0.037065278738737106 | fit/entropy_loss = 1.5085816383361816 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 95 | episode_rewards = 210.97536422295454 | dw_time_elapsed = 39.640139899999895 | fit/surrogate_loss = 0.014459729194641113 | fit/entropy_loss = 1.4589688777923584 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 104 | episode_rewards = 219.69213239234293 | dw_time_elapsed = 42.799521499999855 | fit/surrogate_loss = -0.022906310856342316 | fit/entropy_loss = 1.4569966793060303 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 113 | episode_rewards = 223.59684518464866 | dw_time_elapsed = 45.95344399999999 | fit/surrogate_loss = 0.017424680292606354 | fit/entropy_loss = 1.3951150178909302 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 122 | episode_rewards = 224.41236350103796 | dw_time_elapsed = 49.56607999999983 | fit/surrogate_loss = 0.004816148430109024 | fit/entropy_loss = 1.4010460376739502 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 130 | episode_rewards = 226.05380736764909 | dw_time_elapsed = 52.725632399999995 | fit/surrogate_loss = 0.03384905308485031 | fit/entropy_loss = 1.3061597347259521 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 139 | episode_rewards = 228.1066584575184 | dw_time_elapsed = 55.78553909999982 | fit/surrogate_loss = 0.026625443249940872 | fit/entropy_loss = 1.3302879333496094 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 151 | episode_rewards = 229.1770357819951 | dw_time_elapsed = 58.93875879999996 | fit/surrogate_loss = 0.00917721912264824 | fit/entropy_loss = 1.320055603981018 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 161 | episode_rewards = 230.98270513747272 | dw_time_elapsed = 62.10329579999984 | fit/surrogate_loss = -0.0037215277552604675 | fit/entropy_loss = 1.2033991813659668 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 169 | episode_rewards = 232.3643362656836 | dw_time_elapsed = 65.26390749999996 | fit/surrogate_loss = 0.056070491671562195 | fit/entropy_loss = 1.2498254776000977 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 176 | episode_rewards = 230.4505154573858 | dw_time_elapsed = 68.4007810999999 | fit/surrogate_loss = 0.00834696739912033 | fit/entropy_loss = 1.2498254776000977 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 184 | episode_rewards = 230.7624465782873 | dw_time_elapsed = 71.46558059999984 | fit/surrogate_loss = 0.00834696739912033 | fit/entropy_loss = 1.1027734279632568 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 192 | episode_rewards = 233.5321637560023 | dw_time_elapsed = 74.93287709999981 | fit/surrogate_loss = 0.018298860639333725 | fit/entropy_loss = 1.2248659133911133 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 200 | episode_rewards = 230.7491718826591 | dw_time_elapsed = 78.13646289999997 | fit/surrogate_loss = 0.018298860639333725 | fit/entropy_loss = 1.1251380443572998 |  \n",
      "[INFO] Could not find least used device (nvidia-smi might be missing), use cuda:0 instead \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 11 | episode_rewards = 0.0 | dw_time_elapsed = 3.005157000000054 | fit/surrogate_loss = -0.009301887825131416 | fit/entropy_loss = 1.6016913652420044 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 23 | episode_rewards = 8.564135121729539 | dw_time_elapsed = 6.206942100000106 | fit/surrogate_loss = 0.01943044178187847 | fit/entropy_loss = 1.585842490196228 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 32 | episode_rewards = 42.24529379507735 | dw_time_elapsed = 9.225622899999962 | fit/surrogate_loss = -0.02246786281466484 | fit/entropy_loss = 1.5698751211166382 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 43 | episode_rewards = 14.525314100403605 | dw_time_elapsed = 12.238974800000051 | fit/surrogate_loss = -0.005461228080093861 | fit/entropy_loss = 1.5623104572296143 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 55 | episode_rewards = 12.139826075951056 | dw_time_elapsed = 15.270372599999973 | fit/surrogate_loss = 0.010485071688890457 | fit/entropy_loss = 1.5542117357254028 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 64 | episode_rewards = 95.39570795390375 | dw_time_elapsed = 18.420716699999957 | fit/surrogate_loss = 0.07028709352016449 | fit/entropy_loss = 1.5115797519683838 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 75 | episode_rewards = 131.06699738274662 | dw_time_elapsed = 21.46174670000005 | fit/surrogate_loss = -0.022600460797548294 | fit/entropy_loss = 1.4794914722442627 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 87 | episode_rewards = 156.39731048558588 | dw_time_elapsed = 24.521451500000012 | fit/surrogate_loss = 0.005993187427520752 | fit/entropy_loss = 1.3992210626602173 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 97 | episode_rewards = 159.65059077507559 | dw_time_elapsed = 27.72956260000001 | fit/surrogate_loss = -0.019405635073781013 | fit/entropy_loss = 1.3366246223449707 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 108 | episode_rewards = 172.516607167859 | dw_time_elapsed = 30.74020949999999 | fit/surrogate_loss = 0.02434743195772171 | fit/entropy_loss = 1.3195403814315796 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 120 | episode_rewards = 174.37012871739338 | dw_time_elapsed = 33.787105699999984 | fit/surrogate_loss = 0.03337222337722778 | fit/entropy_loss = 1.277862787246704 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 129 | episode_rewards = 179.79859643320327 | dw_time_elapsed = 36.92787210000006 | fit/surrogate_loss = 0.012879639863967896 | fit/entropy_loss = 1.2311229705810547 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 142 | episode_rewards = 183.07496459145295 | dw_time_elapsed = 40.118036300000085 | fit/surrogate_loss = 0.012352891266345978 | fit/entropy_loss = 1.2144014835357666 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 152 | episode_rewards = 185.64738028937356 | dw_time_elapsed = 43.26646389999996 | fit/surrogate_loss = 0.006447304040193558 | fit/entropy_loss = 1.1589947938919067 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 163 | episode_rewards = 192.70787034229863 | dw_time_elapsed = 46.31548930000008 | fit/surrogate_loss = 0.03788323700428009 | fit/entropy_loss = 1.2139077186584473 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 176 | episode_rewards = 187.9108412079853 | dw_time_elapsed = 49.52109110000015 | fit/surrogate_loss = 0.008073625154793262 | fit/entropy_loss = 1.1802936792373657 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 186 | episode_rewards = 194.5089162184862 | dw_time_elapsed = 52.83364849999998 | fit/surrogate_loss = 0.00959625095129013 | fit/entropy_loss = 1.1384949684143066 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 197 | episode_rewards = 192.74640722165992 | dw_time_elapsed = 56.045801799999936 | fit/surrogate_loss = 0.016091860830783844 | fit/entropy_loss = 1.1597554683685303 |  \n",
      "[INFO] Could not find least used device (nvidia-smi might be missing), use cuda:0 instead \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 12 | episode_rewards = 0.6653994253577282 | dw_time_elapsed = 3.1602839999998196 | fit/surrogate_loss = 0.022261397913098335 | fit/entropy_loss = 1.5972075462341309 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 24 | episode_rewards = 1.331927960187746 | dw_time_elapsed = 6.296501799999987 | fit/surrogate_loss = -0.008576720952987671 | fit/entropy_loss = 1.5701568126678467 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 34 | episode_rewards = 14.390257809182414 | dw_time_elapsed = 9.488254799999822 | fit/surrogate_loss = 0.03383974730968475 | fit/entropy_loss = 1.5577057600021362 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 46 | episode_rewards = 37.78703040956307 | dw_time_elapsed = 12.661822099999881 | fit/surrogate_loss = -0.0012722145766019821 | fit/entropy_loss = 1.553954839706421 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 56 | episode_rewards = 62.77708239918987 | dw_time_elapsed = 15.808956500000022 | fit/surrogate_loss = 0.04908198118209839 | fit/entropy_loss = 1.5394251346588135 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 67 | episode_rewards = 99.06008748074493 | dw_time_elapsed = 18.820097799999985 | fit/surrogate_loss = 0.02778274193406105 | fit/entropy_loss = 1.4844629764556885 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 79 | episode_rewards = 103.4131704720382 | dw_time_elapsed = 21.97897059999991 | fit/surrogate_loss = 0.03222476318478584 | fit/entropy_loss = 1.472140908241272 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 88 | episode_rewards = 133.33203211768387 | dw_time_elapsed = 25.035250399999995 | fit/surrogate_loss = 0.048935018479824066 | fit/entropy_loss = 1.375568151473999 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 99 | episode_rewards = 135.6399539805558 | dw_time_elapsed = 28.080355599999848 | fit/surrogate_loss = 0.04882925748825073 | fit/entropy_loss = 1.3542693853378296 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 112 | episode_rewards = 150.80431280416087 | dw_time_elapsed = 31.276073600000018 | fit/surrogate_loss = 0.022958427667617798 | fit/entropy_loss = 1.3038246631622314 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 122 | episode_rewards = 155.9233426208547 | dw_time_elapsed = 34.43398819999993 | fit/surrogate_loss = 0.037509672343730927 | fit/entropy_loss = 1.2543516159057617 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 134 | episode_rewards = 167.3806982585199 | dw_time_elapsed = 37.61439009999981 | fit/surrogate_loss = 0.018608296290040016 | fit/entropy_loss = 1.1990139484405518 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 144 | episode_rewards = 161.14254830851806 | dw_time_elapsed = 40.722303999999895 | fit/surrogate_loss = 0.04711863771080971 | fit/entropy_loss = 1.1745458841323853 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 156 | episode_rewards = 175.95977195491085 | dw_time_elapsed = 43.88020419999998 | fit/surrogate_loss = 0.02455391362309456 | fit/entropy_loss = 1.10603666305542 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 168 | episode_rewards = 169.71388820728285 | dw_time_elapsed = 47.37949619999995 | fit/surrogate_loss = -0.005761898122727871 | fit/entropy_loss = 1.1613531112670898 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 180 | episode_rewards = 171.30675294402272 | dw_time_elapsed = 50.37972969999987 | fit/surrogate_loss = -0.00389949232339859 | fit/entropy_loss = 1.0951216220855713 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 192 | episode_rewards = 176.8111878148767 | dw_time_elapsed = 53.50579319999997 | fit/surrogate_loss = 0.007501877844333649 | fit/entropy_loss = 1.141865849494934 |  \n",
      "[INFO] Could not find least used device (nvidia-smi might be missing), use cuda:0 instead \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 9 | episode_rewards = 14.233938577131763 | dw_time_elapsed = 3.3957833000001756 | fit/surrogate_loss = 0.03947175294160843 | fit/entropy_loss = 1.5789401531219482 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 19 | episode_rewards = 7.355023239462031 | dw_time_elapsed = 6.405381400000124 | fit/surrogate_loss = 0.0262947678565979 | fit/entropy_loss = 1.5669928789138794 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 30 | episode_rewards = 16.7147638749024 | dw_time_elapsed = 9.607121400000096 | fit/surrogate_loss = 0.020609179511666298 | fit/entropy_loss = 1.550640344619751 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 40 | episode_rewards = 15.397208990560596 | dw_time_elapsed = 13.01284889999988 | fit/surrogate_loss = 0.04080021008849144 | fit/entropy_loss = 1.5524030923843384 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 52 | episode_rewards = 18.580657746338787 | dw_time_elapsed = 16.18051229999992 | fit/surrogate_loss = 0.04059896245598793 | fit/entropy_loss = 1.5292024612426758 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 58 | episode_rewards = 20.502358700762173 | dw_time_elapsed = 19.192538199999944 | fit/surrogate_loss = 0.015477066859602928 | fit/entropy_loss = 1.5030066967010498 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 65 | episode_rewards = 20.441791004325612 | dw_time_elapsed = 22.297826700000314 | fit/surrogate_loss = 0.061735205352306366 | fit/entropy_loss = 1.4843592643737793 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 74 | episode_rewards = 19.852644938596914 | dw_time_elapsed = 25.785781900000075 | fit/surrogate_loss = 0.009225156158208847 | fit/entropy_loss = 1.4686789512634277 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 84 | episode_rewards = 22.132306391043542 | dw_time_elapsed = 28.937478800000008 | fit/surrogate_loss = 0.003328954800963402 | fit/entropy_loss = 1.4337480068206787 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 90 | episode_rewards = 21.85432102091868 | dw_time_elapsed = 31.93753319999996 | fit/surrogate_loss = 0.017684925347566605 | fit/entropy_loss = 1.4021034240722656 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 97 | episode_rewards = 22.050686882097022 | dw_time_elapsed = 35.051558000000114 | fit/surrogate_loss = 0.012803014367818832 | fit/entropy_loss = 1.3805716037750244 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 104 | episode_rewards = 22.21192028346076 | dw_time_elapsed = 38.34805099999994 | fit/surrogate_loss = 0.012803014367818832 | fit/entropy_loss = 1.3805716037750244 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 109 | episode_rewards = 22.543539730357185 | dw_time_elapsed = 41.873821300000145 | fit/surrogate_loss = 0.014284908771514893 | fit/entropy_loss = 1.3584274053573608 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 119 | episode_rewards = 22.27993012971823 | dw_time_elapsed = 45.057837500000005 | fit/surrogate_loss = 0.06243851035833359 | fit/entropy_loss = 1.358439564704895 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 128 | episode_rewards = 22.873382266689433 | dw_time_elapsed = 48.10976750000009 | fit/surrogate_loss = 0.019414013251662254 | fit/entropy_loss = 1.3813772201538086 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 141 | episode_rewards = 22.67341176507304 | dw_time_elapsed = 51.207186900000124 | fit/surrogate_loss = 0.014699671417474747 | fit/entropy_loss = 1.2736501693725586 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 152 | episode_rewards = 23.143892314184022 | dw_time_elapsed = 54.35771590000013 | fit/surrogate_loss = 0.01947631500661373 | fit/entropy_loss = 1.242150068283081 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 165 | episode_rewards = 23.065143785803787 | dw_time_elapsed = 57.52060329999995 | fit/surrogate_loss = -0.014952017925679684 | fit/entropy_loss = 1.2161080837249756 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 176 | episode_rewards = 23.06559656769279 | dw_time_elapsed = 60.70089280000002 | fit/surrogate_loss = -0.0049958014860749245 | fit/entropy_loss = 1.185396671295166 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 188 | episode_rewards = 23.259297158087946 | dw_time_elapsed = 63.7023678999999 | fit/surrogate_loss = 0.01922842487692833 | fit/entropy_loss = 1.1953043937683105 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 200 | episode_rewards = 23.18401637003306 | dw_time_elapsed = 67.10602169999993 | fit/surrogate_loss = -0.014759780839085579 | fit/entropy_loss = 1.1552274227142334 |  \n",
      "[INFO] Could not find least used device (nvidia-smi might be missing), use cuda:0 instead \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 12 | episode_rewards = 6.427110856942653 | dw_time_elapsed = 3.0861197999997785 | fit/surrogate_loss = 0.03518619388341904 | fit/entropy_loss = 1.5776958465576172 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 24 | episode_rewards = 11.010949525988163 | dw_time_elapsed = 6.284904499999811 | fit/surrogate_loss = 0.01954060047864914 | fit/entropy_loss = 1.5554524660110474 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 33 | episode_rewards = 13.897689838065078 | dw_time_elapsed = 9.55198879999989 | fit/surrogate_loss = 0.04988384246826172 | fit/entropy_loss = 1.5145113468170166 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 44 | episode_rewards = 11.76366859365256 | dw_time_elapsed = 12.62315129999979 | fit/surrogate_loss = 0.02607693150639534 | fit/entropy_loss = 1.4826436042785645 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 54 | episode_rewards = 14.82892717522619 | dw_time_elapsed = 15.757825400000002 | fit/surrogate_loss = 0.05911121889948845 | fit/entropy_loss = 1.5527608394622803 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 64 | episode_rewards = 15.497443456298608 | dw_time_elapsed = 19.037288999999873 | fit/surrogate_loss = 0.07111693173646927 | fit/entropy_loss = 1.5393593311309814 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 76 | episode_rewards = 18.091767758751015 | dw_time_elapsed = 22.1771162 | fit/surrogate_loss = 0.009400149807333946 | fit/entropy_loss = 1.5116673707962036 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 88 | episode_rewards = 19.07302749014772 | dw_time_elapsed = 25.597104899999977 | fit/surrogate_loss = -0.009356502443552017 | fit/entropy_loss = 1.4993374347686768 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 101 | episode_rewards = 20.790123146611375 | dw_time_elapsed = 28.743821300000036 | fit/surrogate_loss = 0.01454072818160057 | fit/entropy_loss = 1.4004716873168945 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 112 | episode_rewards = 21.068206926365654 | dw_time_elapsed = 32.17081449999978 | fit/surrogate_loss = -0.002066750079393387 | fit/entropy_loss = 1.3982638120651245 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 124 | episode_rewards = 21.68118213522385 | dw_time_elapsed = 35.17859789999966 | fit/surrogate_loss = 0.0020603537559509277 | fit/entropy_loss = 1.37680184841156 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 136 | episode_rewards = 21.769540598675754 | dw_time_elapsed = 38.65824649999968 | fit/surrogate_loss = 0.027232255786657333 | fit/entropy_loss = 1.2591530084609985 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 148 | episode_rewards = 21.949679541161775 | dw_time_elapsed = 41.65997560000005 | fit/surrogate_loss = -0.007082168012857437 | fit/entropy_loss = 1.2430237531661987 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 160 | episode_rewards = 22.257684636748888 | dw_time_elapsed = 45.07885679999981 | fit/surrogate_loss = 0.0077946484088897705 | fit/entropy_loss = 1.266481876373291 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 172 | episode_rewards = 22.000739099092197 | dw_time_elapsed = 48.19995139999992 | fit/surrogate_loss = 0.00767703540623188 | fit/entropy_loss = 1.2061386108398438 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 184 | episode_rewards = 22.24522805339893 | dw_time_elapsed = 51.594453899999735 | fit/surrogate_loss = 0.012318812310695648 | fit/entropy_loss = 1.1962523460388184 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 196 | episode_rewards = 22.918906875712356 | dw_time_elapsed = 54.66120000000001 | fit/surrogate_loss = 0.012164507061243057 | fit/entropy_loss = 1.0936777591705322 |  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PBall2D': 159.45171787346624, 'BallLevel1': 179.86923372894634, 'BallLevel2': 150.230704241399, 'BallLevel3': 135.7577563601283, 'BallLevel4': 17.95803437104275, 'BallLevel5': 17.449695024722256}\n"
     ]
    }
   ],
   "source": [
    "env_ppo_reward = {}\n",
    "\n",
    "n_episodes = 200\n",
    "horizon = 256\n",
    "nb_runs = 1000\n",
    "\n",
    "for env_index in env_dict.keys():\n",
    "    env = env_dict[env_index] #getting env\n",
    "    agent = PPOAgent(\n",
    "    env, horizon=horizon, gamma=0.99, learning_rate=0.001, eps_clip=0.2, k_epochs=4\n",
    "    ) #define agent\n",
    "    agent.fit(budget=n_episodes,) #training \n",
    "\n",
    "\n",
    "    average_reward = 0\n",
    "    for run in range(nb_runs): #getting average reward on nb_runs runs after training\n",
    "        state = env.reset()\n",
    "        for tt in range(200):\n",
    "            action = agent.policy(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            state = next_state\n",
    "            average_reward += reward\n",
    "    \n",
    "    average_reward = average_reward / nb_runs\n",
    "        \n",
    "    \n",
    "    env_ppo_reward[idx_to_env_dict[env_index]] = average_reward\n",
    "\n",
    "print(env_ppo_reward)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Could not find least used device (nvidia-smi might be missing), use cuda:0 instead \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 6 | episode_rewards = 0.0 | dw_time_elapsed = 3.241626600000018 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 16 | episode_rewards = 0.0 | dw_time_elapsed = 6.330075699999725 | fit/surrogate_loss = -0.001912865787744522 | fit/entropy_loss = 1.3573051691055298 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 24 | episode_rewards = 24.22912399286595 | dw_time_elapsed = 10.436659699999836 | fit/surrogate_loss = -0.0010738624259829521 | fit/entropy_loss = 1.345870018005371 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 31 | episode_rewards = 28.850823419680022 | dw_time_elapsed = 13.918474799999785 | fit/surrogate_loss = -0.0010738624259829521 | fit/entropy_loss = 1.3558253049850464 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 38 | episode_rewards = 39.40049264563073 | dw_time_elapsed = 17.067973599999732 | fit/surrogate_loss = 0.0060933432541787624 | fit/entropy_loss = 1.3432635068893433 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 46 | episode_rewards = 66.0470786856504 | dw_time_elapsed = 20.24375229999987 | fit/surrogate_loss = 0.03832501918077469 | fit/entropy_loss = 1.3486688137054443 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 48 | episode_rewards = 91.88635809616933 | dw_time_elapsed = 23.597902599999998 | fit/surrogate_loss = 0.024414587765932083 | fit/entropy_loss = 1.3486688137054443 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 54 | episode_rewards = 95.38129396861564 | dw_time_elapsed = 26.601944399999866 | fit/surrogate_loss = 0.024414587765932083 | fit/entropy_loss = 1.3257018327713013 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 59 | episode_rewards = 106.32725208654101 | dw_time_elapsed = 30.23049029999993 | fit/surrogate_loss = 0.03978437930345535 | fit/entropy_loss = 1.2887113094329834 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 64 | episode_rewards = 115.9716300856257 | dw_time_elapsed = 34.294225899999674 | fit/surrogate_loss = 0.03978437930345535 | fit/entropy_loss = 1.2887113094329834 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 64 | episode_rewards = 115.9716300856257 | dw_time_elapsed = 38.12791040000002 | fit/surrogate_loss = 0.014306921511888504 | fit/entropy_loss = 1.2887113094329834 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 68 | episode_rewards = 133.44029891627054 | dw_time_elapsed = 42.03736769999978 | fit/surrogate_loss = 0.014306921511888504 | fit/entropy_loss = 1.3130593299865723 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 74 | episode_rewards = 113.57040635628725 | dw_time_elapsed = 45.135230599999886 | fit/surrogate_loss = 0.013995133340358734 | fit/entropy_loss = 1.2716070413589478 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 80 | episode_rewards = 142.48753626305202 | dw_time_elapsed = 49.534272599999895 | fit/surrogate_loss = 0.013628106564283371 | fit/entropy_loss = 1.2716070413589478 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 88 | episode_rewards = 130.00747837673688 | dw_time_elapsed = 53.30116229999976 | fit/surrogate_loss = 0.013628106564283371 | fit/entropy_loss = 1.240516185760498 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 94 | episode_rewards = 162.10793138599243 | dw_time_elapsed = 56.39187939999965 | fit/surrogate_loss = 0.030210301280021667 | fit/entropy_loss = 1.2309693098068237 |  \n",
      "[INFO] Could not find least used device (nvidia-smi might be missing), use cuda:0 instead \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 7 | episode_rewards = 3.932226566245261 | dw_time_elapsed = 3.1191240999996808 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 14 | episode_rewards = 114.53237805698193 | dw_time_elapsed = 6.281284799999867 | fit/surrogate_loss = 0.03503837436437607 | fit/entropy_loss = 1.5873212814331055 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 22 | episode_rewards = 115.10441137376715 | dw_time_elapsed = 9.335643699999764 | fit/surrogate_loss = 0.050185270607471466 | fit/entropy_loss = 1.581439733505249 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 31 | episode_rewards = 126.88642503482846 | dw_time_elapsed = 12.818027299999812 | fit/surrogate_loss = 0.043834298849105835 | fit/entropy_loss = 1.5577218532562256 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 35 | episode_rewards = 145.04471601763166 | dw_time_elapsed = 16.077645800000028 | fit/surrogate_loss = 0.05123947560787201 | fit/entropy_loss = 1.5576870441436768 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 41 | episode_rewards = 151.10111047782718 | dw_time_elapsed = 19.226596900000004 | fit/surrogate_loss = 0.047209132462739944 | fit/entropy_loss = 1.5413002967834473 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 50 | episode_rewards = 157.52894888607284 | dw_time_elapsed = 22.29250039999988 | fit/surrogate_loss = 0.04536716639995575 | fit/entropy_loss = 1.5482163429260254 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 61 | episode_rewards = 177.87314027562394 | dw_time_elapsed = 25.32242670000005 | fit/surrogate_loss = 0.04527324438095093 | fit/entropy_loss = 1.5190404653549194 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 72 | episode_rewards = 201.74200612852675 | dw_time_elapsed = 28.463186199999654 | fit/surrogate_loss = 0.05716807395219803 | fit/entropy_loss = 1.5224571228027344 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 80 | episode_rewards = 205.76028841380236 | dw_time_elapsed = 31.72464549999995 | fit/surrogate_loss = 0.001724187284708023 | fit/entropy_loss = 1.5245555639266968 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 87 | episode_rewards = 202.62967275287343 | dw_time_elapsed = 35.22622079999974 | fit/surrogate_loss = 0.001724187284708023 | fit/entropy_loss = 1.494925856590271 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 89 | episode_rewards = 216.97469954660784 | dw_time_elapsed = 38.587017899999864 | fit/surrogate_loss = -0.03153711184859276 | fit/entropy_loss = 1.4729883670806885 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 96 | episode_rewards = 207.52244394821656 | dw_time_elapsed = 41.77965809999978 | fit/surrogate_loss = 0.02700236067175865 | fit/entropy_loss = 1.4729883670806885 |  \n",
      "[INFO] Could not find least used device (nvidia-smi might be missing), use cuda:0 instead \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 7 | episode_rewards = 0.0 | dw_time_elapsed = 3.1123039999997673 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 11 | episode_rewards = 0.0 | dw_time_elapsed = 6.432753199999752 | fit/surrogate_loss = 0.039988018572330475 | fit/entropy_loss = 1.6041312217712402 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 19 | episode_rewards = 0.4421569820021911 | dw_time_elapsed = 9.719659999999749 | fit/surrogate_loss = 0.01831969805061817 | fit/entropy_loss = 1.5920038223266602 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 25 | episode_rewards = 29.777272578758446 | dw_time_elapsed = 12.760714499999722 | fit/surrogate_loss = 0.014188665896654129 | fit/entropy_loss = 1.5604901313781738 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 32 | episode_rewards = 11.04501565737306 | dw_time_elapsed = 15.836562199999662 | fit/surrogate_loss = 0.014188665896654129 | fit/entropy_loss = 1.5604901313781738 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 35 | episode_rewards = 27.937087016511587 | dw_time_elapsed = 18.90186249999988 | fit/surrogate_loss = 0.01480269804596901 | fit/entropy_loss = 1.5750240087509155 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 41 | episode_rewards = 50.81789463252638 | dw_time_elapsed = 21.99322459999985 | fit/surrogate_loss = 0.008936915546655655 | fit/entropy_loss = 1.5721347332000732 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 47 | episode_rewards = 12.941080798633937 | dw_time_elapsed = 25.02617650000002 | fit/surrogate_loss = 0.008936915546655655 | fit/entropy_loss = 1.5721347332000732 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 51 | episode_rewards = 71.31472572908207 | dw_time_elapsed = 29.168473999999605 | fit/surrogate_loss = 0.02480355277657509 | fit/entropy_loss = 1.523507833480835 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 56 | episode_rewards = 88.97771503413517 | dw_time_elapsed = 32.57318209999994 | fit/surrogate_loss = 0.05078703910112381 | fit/entropy_loss = 1.523507833480835 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 62 | episode_rewards = 89.55328235767415 | dw_time_elapsed = 36.20428349999975 | fit/surrogate_loss = 0.05078703910112381 | fit/entropy_loss = 1.5433584451675415 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 69 | episode_rewards = 74.6305275700515 | dw_time_elapsed = 39.59321349999982 | fit/surrogate_loss = 0.03381399065256119 | fit/entropy_loss = 1.5041594505310059 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 74 | episode_rewards = 117.96485350518988 | dw_time_elapsed = 42.67917849999958 | fit/surrogate_loss = 0.021520286798477173 | fit/entropy_loss = 1.4887386560440063 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 80 | episode_rewards = 126.19140019490179 | dw_time_elapsed = 46.22947929999964 | fit/surrogate_loss = 0.02675732970237732 | fit/entropy_loss = 1.4887386560440063 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 86 | episode_rewards = 139.54179544725903 | dw_time_elapsed = 49.39027109999961 | fit/surrogate_loss = 0.02675732970237732 | fit/entropy_loss = 1.4183253049850464 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 93 | episode_rewards = 155.87684543846677 | dw_time_elapsed = 52.605321099999856 | fit/surrogate_loss = 0.057099729776382446 | fit/entropy_loss = 1.4338436126708984 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 98 | episode_rewards = 155.11718999059713 | dw_time_elapsed = 55.7682120999998 | fit/surrogate_loss = 0.02020636945962906 | fit/entropy_loss = 1.3955373764038086 |  \n",
      "[INFO] Could not find least used device (nvidia-smi might be missing), use cuda:0 instead \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 9 | episode_rewards = 0.0 | dw_time_elapsed = 3.1196414000000914 | fit/surrogate_loss = 0.014981020241975784 | fit/entropy_loss = 1.585809350013733 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 18 | episode_rewards = 0.0 | dw_time_elapsed = 6.253598400000101 | fit/surrogate_loss = 0.02594120055437088 | fit/entropy_loss = 1.5940344333648682 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 28 | episode_rewards = 43.31209891805892 | dw_time_elapsed = 9.362862599999971 | fit/surrogate_loss = 0.0018200380727648735 | fit/entropy_loss = 1.5987290143966675 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 38 | episode_rewards = 0.09462179318548192 | dw_time_elapsed = 12.60704590000023 | fit/surrogate_loss = 0.004986187443137169 | fit/entropy_loss = 1.5694124698638916 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 47 | episode_rewards = 22.211752043913805 | dw_time_elapsed = 15.632702000000336 | fit/surrogate_loss = -0.015556399710476398 | fit/entropy_loss = 1.5368845462799072 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 56 | episode_rewards = 3.3813311021854258 | dw_time_elapsed = 18.801090900000418 | fit/surrogate_loss = 0.04447484761476517 | fit/entropy_loss = 1.5390537977218628 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 64 | episode_rewards = 32.6420146986143 | dw_time_elapsed = 22.053874800000358 | fit/surrogate_loss = 0.017985213547945023 | fit/entropy_loss = 1.5344815254211426 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 74 | episode_rewards = 61.3123343383895 | dw_time_elapsed = 25.227460900000096 | fit/surrogate_loss = 0.005021963268518448 | fit/entropy_loss = 1.4927208423614502 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 83 | episode_rewards = 90.18938970037226 | dw_time_elapsed = 28.45052680000026 | fit/surrogate_loss = 0.019097834825515747 | fit/entropy_loss = 1.486987829208374 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 93 | episode_rewards = 83.20046571761603 | dw_time_elapsed = 31.579301800000394 | fit/surrogate_loss = 0.006563737988471985 | fit/entropy_loss = 1.4617242813110352 |  \n",
      "[INFO] Could not find least used device (nvidia-smi might be missing), use cuda:0 instead \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 8 | episode_rewards = 2.9941096902797275 | dw_time_elapsed = 3.012818100000004 | fit/surrogate_loss = 0.02362416870892048 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 17 | episode_rewards = 12.563720015147807 | dw_time_elapsed = 6.053063699999711 | fit/surrogate_loss = 0.04595457762479782 | fit/entropy_loss = 1.562131404876709 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 27 | episode_rewards = 15.46133021992417 | dw_time_elapsed = 9.247198699999899 | fit/surrogate_loss = 0.030630923807621002 | fit/entropy_loss = 1.528125286102295 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 36 | episode_rewards = 16.355133836514163 | dw_time_elapsed = 12.326970699999947 | fit/surrogate_loss = 0.03854537755250931 | fit/entropy_loss = 1.5275225639343262 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 46 | episode_rewards = 15.884885933693695 | dw_time_elapsed = 15.66018559999975 | fit/surrogate_loss = 0.046581052243709564 | fit/entropy_loss = 1.5414625406265259 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 55 | episode_rewards = 15.528522666862026 | dw_time_elapsed = 18.746437100000094 | fit/surrogate_loss = 0.03813423961400986 | fit/entropy_loss = 1.5631115436553955 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 64 | episode_rewards = 15.032904302854485 | dw_time_elapsed = 21.80696369999987 | fit/surrogate_loss = 0.05644787847995758 | fit/entropy_loss = 1.5727884769439697 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 72 | episode_rewards = 17.227585993225844 | dw_time_elapsed = 25.162772700000005 | fit/surrogate_loss = 0.0640629380941391 | fit/entropy_loss = 1.56023108959198 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 81 | episode_rewards = 20.06651526370527 | dw_time_elapsed = 28.225401599999714 | fit/surrogate_loss = 0.028012558817863464 | fit/entropy_loss = 1.5065374374389648 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 90 | episode_rewards = 20.596175864311032 | dw_time_elapsed = 31.334811799999898 | fit/surrogate_loss = 0.019678860902786255 | fit/entropy_loss = 1.4688341617584229 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 99 | episode_rewards = 21.760983270593854 | dw_time_elapsed = 34.39803639999991 | fit/surrogate_loss = 0.029697898775339127 | fit/entropy_loss = 1.5071144104003906 |  \n",
      "[INFO] Could not find least used device (nvidia-smi might be missing), use cuda:0 instead \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 3 | episode_rewards = 1.3830566534783835 | dw_time_elapsed = 3.4480765999996947 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 7 | episode_rewards = 0.07440467587455793 | dw_time_elapsed = 7.505847099999755 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 8 | episode_rewards = 12.363622912580553 | dw_time_elapsed = 11.38638149999997 | fit/surrogate_loss = 0.0303761288523674 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 11 | episode_rewards = 6.267880397368787 | dw_time_elapsed = 15.217350299999907 | fit/surrogate_loss = 0.0303761288523674 | fit/entropy_loss = 1.5968412160873413 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 14 | episode_rewards = 3.006890036996076 | dw_time_elapsed = 18.33005430000003 | fit/surrogate_loss = 0.0303761288523674 | fit/entropy_loss = 1.5968412160873413 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 16 | episode_rewards = 7.73230201911475 | dw_time_elapsed = 23.116071699999793 | fit/surrogate_loss = 0.015243159607052803 | fit/entropy_loss = 1.5968412160873413 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 19 | episode_rewards = 9.664354473810981 | dw_time_elapsed = 27.168089399999644 | fit/surrogate_loss = 0.015243159607052803 | fit/entropy_loss = 1.5850145816802979 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 22 | episode_rewards = 9.942292232178639 | dw_time_elapsed = 30.25713319999977 | fit/surrogate_loss = 0.015243159607052803 | fit/entropy_loss = 1.5850145816802979 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 24 | episode_rewards = 10.902205086289596 | dw_time_elapsed = 35.287441099999796 | fit/surrogate_loss = 0.04299493879079819 | fit/entropy_loss = 1.5850145816802979 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 27 | episode_rewards = 12.759428054272192 | dw_time_elapsed = 38.664653199999975 | fit/surrogate_loss = 0.04299493879079819 | fit/entropy_loss = 1.5615849494934082 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 30 | episode_rewards = 15.181218137232129 | dw_time_elapsed = 41.98203769999964 | fit/surrogate_loss = 0.04299493879079819 | fit/entropy_loss = 1.5615849494934082 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 32 | episode_rewards = 14.474321742298644 | dw_time_elapsed = 46.81895039999972 | fit/surrogate_loss = 0.05224727839231491 | fit/entropy_loss = 1.5615849494934082 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 35 | episode_rewards = 15.160730367330148 | dw_time_elapsed = 50.35787759999994 | fit/surrogate_loss = 0.05224727839231491 | fit/entropy_loss = 1.5227445363998413 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 38 | episode_rewards = 15.62898652411071 | dw_time_elapsed = 53.831764699999894 | fit/surrogate_loss = 0.05224727839231491 | fit/entropy_loss = 1.5227445363998413 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 40 | episode_rewards = 14.865096994494754 | dw_time_elapsed = 57.08593289999999 | fit/surrogate_loss = 0.05224727839231491 | fit/entropy_loss = 1.5227445363998413 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 41 | episode_rewards = 14.963708906169181 | dw_time_elapsed = 60.61052449999988 | fit/surrogate_loss = 0.024001210927963257 | fit/entropy_loss = 1.5167832374572754 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 45 | episode_rewards = 14.434450198143807 | dw_time_elapsed = 64.72600639999973 | fit/surrogate_loss = 0.024001210927963257 | fit/entropy_loss = 1.5167832374572754 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 48 | episode_rewards = 16.809161719474602 | dw_time_elapsed = 72.3726531999996 | fit/surrogate_loss = 0.04032101109623909 | fit/entropy_loss = 1.5167832374572754 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 53 | episode_rewards = 16.807015899233395 | dw_time_elapsed = 75.86367529999961 | fit/surrogate_loss = 0.04032101109623909 | fit/entropy_loss = 1.4866842031478882 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 56 | episode_rewards = 18.914276188632638 | dw_time_elapsed = 78.97273379999979 | fit/surrogate_loss = -0.00242561474442482 | fit/entropy_loss = 1.4866842031478882 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 64 | episode_rewards = 19.19612886212652 | dw_time_elapsed = 82.5310959999997 | fit/surrogate_loss = 0.03904123976826668 | fit/entropy_loss = 1.4902063608169556 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 72 | episode_rewards = 17.892422857489606 | dw_time_elapsed = 85.72255879999966 | fit/surrogate_loss = 0.03904123976826668 | fit/entropy_loss = 1.525969386100769 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 78 | episode_rewards = 19.422685867435035 | dw_time_elapsed = 89.13394819999985 | fit/surrogate_loss = 0.0032778438180685043 | fit/entropy_loss = 1.4657838344573975 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 81 | episode_rewards = 20.727112219139883 | dw_time_elapsed = 92.70092479999994 | fit/surrogate_loss = -0.0035567302256822586 | fit/entropy_loss = 1.4983361959457397 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 87 | episode_rewards = 19.905753329688928 | dw_time_elapsed = 96.26353859999972 | fit/surrogate_loss = -0.0035567302256822586 | fit/entropy_loss = 1.4983361959457397 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 90 | episode_rewards = 20.939302352320684 | dw_time_elapsed = 99.46573869999975 | fit/surrogate_loss = 0.025087684392929077 | fit/entropy_loss = 1.4761078357696533 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 96 | episode_rewards = 20.28003337105779 | dw_time_elapsed = 103.10859199999959 | fit/surrogate_loss = 0.025087684392929077 | fit/entropy_loss = 1.4761078357696533 |  \n",
      "[INFO] [PPO[worker: -1]] | max_global_step = 99 | episode_rewards = 21.412221986695187 | dw_time_elapsed = 106.52874909999991 | fit/surrogate_loss = 0.05509712174534798 | fit/entropy_loss = 1.3923377990722656 |  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PBall2D': 130.56481848922755, 'BallLevel1': 166.74865455393302, 'BallLevel2': 123.35901626606004, 'BallLevel3': 78.27835915007876, 'BallLevel4': 16.584381609302667, 'BallLevel5': 16.25855410086959}\n"
     ]
    }
   ],
   "source": [
    "env_ppo_reward = {}\n",
    "\n",
    "n_episodes = 100\n",
    "horizon = 256\n",
    "nb_runs = 1000\n",
    "\n",
    "for env_index in env_dict.keys():\n",
    "    env = env_dict[env_index] #getting env\n",
    "    agent = PPOAgent(\n",
    "    env, horizon=horizon, gamma=0.99, learning_rate=0.001, eps_clip=0.2, k_epochs=4\n",
    "    ) #define agent\n",
    "    agent.fit(budget=n_episodes,) #training \n",
    "\n",
    "\n",
    "    average_reward = 0\n",
    "    for run in range(nb_runs): #getting average reward on nb_runs runs after training\n",
    "        state = env.reset()\n",
    "        for tt in range(200):\n",
    "            action = agent.policy(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            state = next_state\n",
    "            average_reward += reward\n",
    "    \n",
    "    average_reward = average_reward / nb_runs\n",
    "        \n",
    "    \n",
    "    env_ppo_reward[idx_to_env_dict[env_index]] = average_reward\n",
    "\n",
    "print(env_ppo_reward)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "877e635d77654b4bbaf40ac73f166c6702f150ac966450346b4e10ac33844dc6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
